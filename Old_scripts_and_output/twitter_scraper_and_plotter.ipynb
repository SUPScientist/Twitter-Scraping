{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Twitter data by inputting a Twitter handle\n",
    "\n",
    "Code is a modified version of that which can be found here:\n",
    "- https://www.promptcloud.com/blog/scrape-twitter-data-using-python-r/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Twitter API credentials\n",
    "Credentials are stored in a non-git-tracked repo in order to (attempt to) hide them from the public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../twitter_credentials.json') as cred_data:\n",
    "    info = json.load(cred_data)\n",
    "    consumer_key = info['CONSUMER_KEY']\n",
    "    consumer_secret = info['CONSUMER_SECRET']\n",
    "    access_key = info['ACCESS_KEY']\n",
    "    access_secret = info['ACCESS_SECRET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get all tweets for a given handle\n",
    "- authenticate using Twitter developer account credentials\n",
    "- determine number of tweets for that user\n",
    "- loop through tweets and save information about them in a CSV file for later use\n",
    "\n",
    "NB: Twitter allows access to only 3240 tweets via this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tweets(screen_name):\n",
    "\n",
    "    # Authorization and initialization\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    # initialization of a list to hold all Tweets\n",
    "    all_the_tweets = []\n",
    "\n",
    "    # We will get the tweets with multiple requests of 200 tweets each\n",
    "    new_tweets = api.user_timeline(screen_name=screen_name, count=200)\n",
    "\n",
    "    # saving the most recent tweets\n",
    "    all_the_tweets.extend(new_tweets)\n",
    "\n",
    "    # save id of 1 less than the oldest tweet\n",
    "\n",
    "    oldest_tweet = all_the_tweets[-1].id - 1\n",
    "\n",
    "    # grabbing tweets till none are left\n",
    "\n",
    "    while len(new_tweets) > 0:\n",
    "        # The max_id param will be used subsequently to prevent duplicates\n",
    "        new_tweets = api.user_timeline(screen_name=screen_name,\n",
    "        count=200, max_id=oldest_tweet)\n",
    "\n",
    "        # save most recent tweets\n",
    "        all_the_tweets.extend(new_tweets)\n",
    "\n",
    "        # id is updated to oldest tweet - 1 to keep track\n",
    "        oldest_tweet = all_the_tweets[-1].id - 1\n",
    "        print ('...%s tweets have been downloaded so far' % len(all_the_tweets))\n",
    "\n",
    "        # transforming the tweets into a 2D array that will be used to populate the csv\n",
    "        outtweets = [[tweet.id_str, tweet.created_at, tweet.favorite_count, tweet.retweet_count,\n",
    "        tweet.text.encode('utf-8')] for tweet in all_the_tweets]\n",
    "\n",
    "    # writing to the csv file\n",
    "    with open(screen_name + '_tweets.csv', 'w', encoding='utf8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['id', 'created_at', 'favorites', 'retweets', 'text'])\n",
    "        writer.writerows(outtweets)\n",
    "        \n",
    "    print(screen_name + '_tweets.csv has been created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the function above and, in doing so, create the CSV file with tweet details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...400 tweets have been downloaded so far\n",
      "...600 tweets have been downloaded so far\n",
      "...800 tweets have been downloaded so far\n",
      "...1000 tweets have been downloaded so far\n",
      "...1200 tweets have been downloaded so far\n",
      "...1400 tweets have been downloaded so far\n",
      "...1600 tweets have been downloaded so far\n",
      "...1800 tweets have been downloaded so far\n",
      "...2000 tweets have been downloaded so far\n",
      "...2200 tweets have been downloaded so far\n",
      "...2400 tweets have been downloaded so far\n",
      "...2600 tweets have been downloaded so far\n",
      "...2800 tweets have been downloaded so far\n",
      "...3000 tweets have been downloaded so far\n",
      "...3200 tweets have been downloaded so far\n",
      "...3221 tweets have been downloaded so far\n",
      "...3221 tweets have been downloaded so far\n",
      "MontereyAq_tweets.csv has been created\n"
     ]
    }
   ],
   "source": [
    "# Enter the twitter handle of the person concerned\n",
    "# twitter_handle = input(\"Enter the twitter handle of the person whose tweets you want to download:- \")\n",
    "twitter_handle = 'MontereyAq'\n",
    "get_all_tweets(twitter_handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in CSV as a pandas dataframe for subsequent analysis\n",
    "Could have written all data above to dataframe instead of CSV but seems worthwhile keeping the two pieces separate so that running the analysis does not require running the scraping code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_at</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-05-09 00:09:18</th>\n",
       "      <td>1126277931024564224</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>b'@ramaham7 @lulu197140 https://t.co/gDy95F5xMd'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-08 23:59:46</th>\n",
       "      <td>1126275531886870529</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b\"@aimeeetay @RaptorsTooth66 we really shouldn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-08 23:52:05</th>\n",
       "      <td>1126273596127465472</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>b'@winterhazelly @franzanth Yes they are! We h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-08 22:57:15</th>\n",
       "      <td>1126259800419946497</td>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "      <td>b'RT @juliepackard: Happy 93rd birthday to Sir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-08 22:31:03</th>\n",
       "      <td>1126253205317230592</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>b'@Scripps_Ocean aww lookit the cutethulhu we ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  favorites  retweets  \\\n",
       "created_at                                                      \n",
       "2019-05-09 00:09:18  1126277931024564224          3         0   \n",
       "2019-05-08 23:59:46  1126275531886870529          0         0   \n",
       "2019-05-08 23:52:05  1126273596127465472          2         0   \n",
       "2019-05-08 22:57:15  1126259800419946497          0       228   \n",
       "2019-05-08 22:31:03  1126253205317230592         47         4   \n",
       "\n",
       "                                                                  text  \n",
       "created_at                                                              \n",
       "2019-05-09 00:09:18   b'@ramaham7 @lulu197140 https://t.co/gDy95F5xMd'  \n",
       "2019-05-08 23:59:46  b\"@aimeeetay @RaptorsTooth66 we really shouldn...  \n",
       "2019-05-08 23:52:05  b'@winterhazelly @franzanth Yes they are! We h...  \n",
       "2019-05-08 22:57:15  b'RT @juliepackard: Happy 93rd birthday to Sir...  \n",
       "2019-05-08 22:31:03  b'@Scripps_Ocean aww lookit the cutethulhu we ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets = pd.read_csv(twitter_handle + '_tweets.csv', parse_dates = [1])\n",
    "df_tweets.set_index('created_at', inplace = True, drop = True)\n",
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add columns to detect occurrence of keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['kelp', 'plankton', 'cuttlefish', 'ray', 'shark', 'bass', 'jelly', 'dolphin', 'whale', 'puffin', 'penguin', 'squid', 'mola', 'octopus']\n",
    "\n",
    "col_name_list = []\n",
    "# for word in keywords:\n",
    "#     col_name = 'contains_word_' + word\n",
    "#     col_name_list.append(col_name)\n",
    "#     df_tweets[col_name] = df_tweets.apply(lambda row: row.favorites if word in row.text else 0, axis=1)\n",
    "\n",
    "for word in keywords:\n",
    "    col_name = 'contains_word_' + word\n",
    "    col_name_list.append(col_name)\n",
    "    df_tweets[col_name] = df_tweets.apply(lambda row: word if word in row.text else None, axis=1)\n",
    "    \n",
    "df_tweets['url'] = df_tweets.apply(lambda row: 'https://twitter.com/'+twitter_handle+'/status/'+str(row.id), axis=1)\n",
    "df_tweets['hyperlink'] = df_tweets.apply(lambda row: '<a href=\\\"'+row.url+'\\\">'+str(row.favorites)+' favorites for this tweet!</a>', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "      <th>contains_word_kelp</th>\n",
       "      <th>contains_word_plankton</th>\n",
       "      <th>contains_word_cuttlefish</th>\n",
       "      <th>contains_word_ray</th>\n",
       "      <th>contains_word_shark</th>\n",
       "      <th>contains_word_bass</th>\n",
       "      <th>contains_word_jelly</th>\n",
       "      <th>contains_word_dolphin</th>\n",
       "      <th>contains_word_whale</th>\n",
       "      <th>contains_word_puffin</th>\n",
       "      <th>contains_word_penguin</th>\n",
       "      <th>contains_word_squid</th>\n",
       "      <th>contains_word_mola</th>\n",
       "      <th>contains_word_octopus</th>\n",
       "      <th>url</th>\n",
       "      <th>hyperlink</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_at</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-05-09 00:09:18</th>\n",
       "      <td>1126277931024564224</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>b'@ramaham7 @lulu197140 https://t.co/gDy95F5xMd'</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://twitter.com/MontereyAq/status/11262779...</td>\n",
       "      <td>&lt;a href=\"https://twitter.com/MontereyAq/status...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-08 23:59:46</th>\n",
       "      <td>1126275531886870529</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b\"@aimeeetay @RaptorsTooth66 we really shouldn...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://twitter.com/MontereyAq/status/11262755...</td>\n",
       "      <td>&lt;a href=\"https://twitter.com/MontereyAq/status...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-08 23:52:05</th>\n",
       "      <td>1126273596127465472</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>b'@winterhazelly @franzanth Yes they are! We h...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://twitter.com/MontereyAq/status/11262735...</td>\n",
       "      <td>&lt;a href=\"https://twitter.com/MontereyAq/status...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-08 22:57:15</th>\n",
       "      <td>1126259800419946497</td>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "      <td>b'RT @juliepackard: Happy 93rd birthday to Sir...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://twitter.com/MontereyAq/status/11262598...</td>\n",
       "      <td>&lt;a href=\"https://twitter.com/MontereyAq/status...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-08 22:31:03</th>\n",
       "      <td>1126253205317230592</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>b'@Scripps_Ocean aww lookit the cutethulhu we ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://twitter.com/MontereyAq/status/11262532...</td>\n",
       "      <td>&lt;a href=\"https://twitter.com/MontereyAq/status...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  favorites  retweets  \\\n",
       "created_at                                                      \n",
       "2019-05-09 00:09:18  1126277931024564224          3         0   \n",
       "2019-05-08 23:59:46  1126275531886870529          0         0   \n",
       "2019-05-08 23:52:05  1126273596127465472          2         0   \n",
       "2019-05-08 22:57:15  1126259800419946497          0       228   \n",
       "2019-05-08 22:31:03  1126253205317230592         47         4   \n",
       "\n",
       "                                                                  text  \\\n",
       "created_at                                                               \n",
       "2019-05-09 00:09:18   b'@ramaham7 @lulu197140 https://t.co/gDy95F5xMd'   \n",
       "2019-05-08 23:59:46  b\"@aimeeetay @RaptorsTooth66 we really shouldn...   \n",
       "2019-05-08 23:52:05  b'@winterhazelly @franzanth Yes they are! We h...   \n",
       "2019-05-08 22:57:15  b'RT @juliepackard: Happy 93rd birthday to Sir...   \n",
       "2019-05-08 22:31:03  b'@Scripps_Ocean aww lookit the cutethulhu we ...   \n",
       "\n",
       "                    contains_word_kelp contains_word_plankton  \\\n",
       "created_at                                                      \n",
       "2019-05-09 00:09:18               None                   None   \n",
       "2019-05-08 23:59:46               None                   None   \n",
       "2019-05-08 23:52:05               None                   None   \n",
       "2019-05-08 22:57:15               None                   None   \n",
       "2019-05-08 22:31:03               None                   None   \n",
       "\n",
       "                    contains_word_cuttlefish contains_word_ray  \\\n",
       "created_at                                                       \n",
       "2019-05-09 00:09:18                     None              None   \n",
       "2019-05-08 23:59:46                     None              None   \n",
       "2019-05-08 23:52:05                     None              None   \n",
       "2019-05-08 22:57:15                     None              None   \n",
       "2019-05-08 22:31:03                     None              None   \n",
       "\n",
       "                    contains_word_shark contains_word_bass  \\\n",
       "created_at                                                   \n",
       "2019-05-09 00:09:18                None               None   \n",
       "2019-05-08 23:59:46                None               None   \n",
       "2019-05-08 23:52:05                None               None   \n",
       "2019-05-08 22:57:15                None               None   \n",
       "2019-05-08 22:31:03                None               None   \n",
       "\n",
       "                    contains_word_jelly contains_word_dolphin  \\\n",
       "created_at                                                      \n",
       "2019-05-09 00:09:18                None                  None   \n",
       "2019-05-08 23:59:46                None                  None   \n",
       "2019-05-08 23:52:05                None                  None   \n",
       "2019-05-08 22:57:15                None                  None   \n",
       "2019-05-08 22:31:03                None                  None   \n",
       "\n",
       "                    contains_word_whale contains_word_puffin  \\\n",
       "created_at                                                     \n",
       "2019-05-09 00:09:18                None                 None   \n",
       "2019-05-08 23:59:46                None                 None   \n",
       "2019-05-08 23:52:05                None                 None   \n",
       "2019-05-08 22:57:15                None                 None   \n",
       "2019-05-08 22:31:03                None                 None   \n",
       "\n",
       "                    contains_word_penguin contains_word_squid  \\\n",
       "created_at                                                      \n",
       "2019-05-09 00:09:18                  None                None   \n",
       "2019-05-08 23:59:46                  None                None   \n",
       "2019-05-08 23:52:05                  None                None   \n",
       "2019-05-08 22:57:15                  None                None   \n",
       "2019-05-08 22:31:03                  None                None   \n",
       "\n",
       "                    contains_word_mola contains_word_octopus  \\\n",
       "created_at                                                     \n",
       "2019-05-09 00:09:18               None                  None   \n",
       "2019-05-08 23:59:46               None                  None   \n",
       "2019-05-08 23:52:05               None                  None   \n",
       "2019-05-08 22:57:15               None                  None   \n",
       "2019-05-08 22:31:03               None                  None   \n",
       "\n",
       "                                                                   url  \\\n",
       "created_at                                                               \n",
       "2019-05-09 00:09:18  https://twitter.com/MontereyAq/status/11262779...   \n",
       "2019-05-08 23:59:46  https://twitter.com/MontereyAq/status/11262755...   \n",
       "2019-05-08 23:52:05  https://twitter.com/MontereyAq/status/11262735...   \n",
       "2019-05-08 22:57:15  https://twitter.com/MontereyAq/status/11262598...   \n",
       "2019-05-08 22:31:03  https://twitter.com/MontereyAq/status/11262532...   \n",
       "\n",
       "                                                             hyperlink  \n",
       "created_at                                                              \n",
       "2019-05-09 00:09:18  <a href=\"https://twitter.com/MontereyAq/status...  \n",
       "2019-05-08 23:59:46  <a href=\"https://twitter.com/MontereyAq/status...  \n",
       "2019-05-08 23:52:05  <a href=\"https://twitter.com/MontereyAq/status...  \n",
       "2019-05-08 22:57:15  <a href=\"https://twitter.com/MontereyAq/status...  \n",
       "2019-05-08 22:31:03  <a href=\"https://twitter.com/MontereyAq/status...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['contains_word_kelp',\n",
       " 'contains_word_plankton',\n",
       " 'contains_word_cuttlefish',\n",
       " 'contains_word_ray',\n",
       " 'contains_word_shark',\n",
       " 'contains_word_bass',\n",
       " 'contains_word_jelly',\n",
       " 'contains_word_dolphin',\n",
       " 'contains_word_whale',\n",
       " 'contains_word_puffin',\n",
       " 'contains_word_penguin',\n",
       " 'contains_word_squid',\n",
       " 'contains_word_mola',\n",
       " 'contains_word_octopus']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_name_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Plotly plot and append new traces with tweet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_traces = []\n",
    "\n",
    "for word in keywords:\n",
    "    col_name = 'contains_word_' + word\n",
    "    trace = go.Scatter(\n",
    "        x = df_tweets.index,\n",
    "        y = df_tweets[col_name],\n",
    "        mode = 'markers',\n",
    "        marker = dict(\n",
    "            size = df_tweets['favorites']/50,\n",
    "        ),\n",
    "        text = df_tweets['hyperlink'], \n",
    "        hoverinfo = 'text'\n",
    "    )\n",
    "    \n",
    "    plotly_traces.append(trace)\n",
    "    \n",
    "# oddly limit setting is not automatic... some hidden NaT, I suppose?\n",
    "layout = go.Layout(\n",
    "    xaxis=dict(\n",
    "        range=[min(df_tweets.index), max(df_tweets.index)] \n",
    "    ),\n",
    "    showlegend = False,\n",
    "    hovermode = 'closest'\n",
    ")\n",
    "    \n",
    "fig = dict(data = plotly_traces, layout = layout)\n",
    "plot_url = plotly.offline.plot(fig, filename='tweet_frequency.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "js_div = plotly.offline.plot(fig, include_plotlyjs=False, output_type='div')\n",
    "js_txt_name = 'montereyAq_twitter.txt'\n",
    "with open(js_txt_name, 'w+') as f:\n",
    "     f.write(js_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
