{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Twitter data by inputting a Twitter handle\n",
    "\n",
    "Code is a modified version of that which can be found here:\n",
    "- https://www.promptcloud.com/blog/scrape-twitter-data-using-python-r/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Twitter API credentials\n",
    "Credentials are stored in a non-git-tracked repo in order to (attempt to) hide them from the public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../twitter_credentials.json') as cred_data:\n",
    "    info = json.load(cred_data)\n",
    "    consumer_key = info['CONSUMER_KEY']\n",
    "    consumer_secret = info['CONSUMER_SECRET']\n",
    "    access_key = info['ACCESS_KEY']\n",
    "    access_secret = info['ACCESS_SECRET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get all tweets for a given handle\n",
    "- authenticate using Twitter developer account credentials\n",
    "- determine number of tweets for that user\n",
    "- loop through tweets and save information about them in a CSV file for later use\n",
    "\n",
    "NB: Twitter allows access to only 3240 tweets via this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tweets(screen_name):\n",
    "\n",
    "    # Authorization and initialization\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    # initialization of a list to hold all Tweets\n",
    "    all_the_tweets = []\n",
    "\n",
    "    # We will get the tweets with multiple requests of 200 tweets each\n",
    "    new_tweets = api.user_timeline(screen_name=screen_name, count=200)\n",
    "\n",
    "    # saving the most recent tweets\n",
    "    all_the_tweets.extend(new_tweets)\n",
    "\n",
    "    # save id of 1 less than the oldest tweet\n",
    "\n",
    "    oldest_tweet = all_the_tweets[-1].id - 1\n",
    "\n",
    "    # grabbing tweets till none are left\n",
    "\n",
    "    while len(new_tweets) > 0:\n",
    "        # The max_id param will be used subsequently to prevent duplicates\n",
    "        new_tweets = api.user_timeline(screen_name=screen_name,\n",
    "        count=200, max_id=oldest_tweet)\n",
    "\n",
    "        # save most recent tweets\n",
    "        all_the_tweets.extend(new_tweets)\n",
    "\n",
    "        # id is updated to oldest tweet - 1 to keep track\n",
    "        oldest_tweet = all_the_tweets[-1].id - 1\n",
    "        print ('...%s tweets have been downloaded so far' % len(all_the_tweets))\n",
    "\n",
    "        # transforming the tweets into a 2D array that will be used to populate the csv\n",
    "        outtweets = [[tweet.id_str, tweet.created_at, tweet.favorite_count, tweet.retweet_count,\n",
    "        tweet.text.encode('utf-8')] for tweet in all_the_tweets]\n",
    "\n",
    "    # writing to the csv file\n",
    "    with open(screen_name + '_tweets.csv', 'w', encoding='utf8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['id', 'created_at', 'favorites', 'retweets', 'text'])\n",
    "        writer.writerows(outtweets)\n",
    "        \n",
    "    print(screen_name + '_tweets.csv has been created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the function above and, in doing so, create the CSV file with tweet details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...400 tweets have been downloaded so far\n",
      "...600 tweets have been downloaded so far\n",
      "...800 tweets have been downloaded so far\n",
      "...1000 tweets have been downloaded so far\n",
      "...1200 tweets have been downloaded so far\n",
      "...1400 tweets have been downloaded so far\n",
      "...1600 tweets have been downloaded so far\n",
      "...1800 tweets have been downloaded so far\n",
      "...2000 tweets have been downloaded so far\n",
      "...2200 tweets have been downloaded so far\n",
      "...2400 tweets have been downloaded so far\n",
      "...2600 tweets have been downloaded so far\n",
      "...2800 tweets have been downloaded so far\n",
      "...3000 tweets have been downloaded so far\n",
      "...3200 tweets have been downloaded so far\n",
      "...3232 tweets have been downloaded so far\n",
      "...3232 tweets have been downloaded so far\n",
      "MontereyAq_tweets.csv has been created\n"
     ]
    }
   ],
   "source": [
    "# Enter the twitter handle of the person concerned\n",
    "# twitter_handle = input(\"Enter the twitter handle of the person whose tweets you want to download:- \")\n",
    "twitter_handle = 'MontereyAq'\n",
    "get_all_tweets(twitter_handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in CSV as a pandas dataframe for subsequent analysis\n",
    "Could have written all data above to dataframe instead of CSV but seems worthwhile keeping the two pieces separate so that running the analysis does not require running the scraping code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_at</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-05-07 22:58:04</th>\n",
       "      <td>1125897614359007233</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>b'@Squidpastry ty mr mola fren'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-07 22:48:33</th>\n",
       "      <td>1125895219847688192</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>b\"@Squidpastry Like new rubber when it's new, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-07 22:47:39</th>\n",
       "      <td>1125894996018679809</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>b'@pistrix the wild Monterey Bay has that pate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-07 22:25:25</th>\n",
       "      <td>1125889400091463680</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>b'@kumaberi Hope to sea you soon!'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-07 22:25:07</th>\n",
       "      <td>1125889325290233856</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>b'@hcf64 1. Think like a kelp\\n2. Hard substra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  favorites  retweets  \\\n",
       "created_at                                                      \n",
       "2019-05-07 22:58:04  1125897614359007233          2         0   \n",
       "2019-05-07 22:48:33  1125895219847688192          1         0   \n",
       "2019-05-07 22:47:39  1125894996018679809          2         0   \n",
       "2019-05-07 22:25:25  1125889400091463680          1         0   \n",
       "2019-05-07 22:25:07  1125889325290233856          4         0   \n",
       "\n",
       "                                                                  text  \n",
       "created_at                                                              \n",
       "2019-05-07 22:58:04                    b'@Squidpastry ty mr mola fren'  \n",
       "2019-05-07 22:48:33  b\"@Squidpastry Like new rubber when it's new, ...  \n",
       "2019-05-07 22:47:39  b'@pistrix the wild Monterey Bay has that pate...  \n",
       "2019-05-07 22:25:25                 b'@kumaberi Hope to sea you soon!'  \n",
       "2019-05-07 22:25:07  b'@hcf64 1. Think like a kelp\\n2. Hard substra...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets = pd.read_csv(twitter_handle + '_tweets.csv', parse_dates = [1])\n",
    "df_tweets.set_index('created_at', inplace = True, drop = True)\n",
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add columns to detect occurrence of keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['kelp', 'bass', 'jelly', 'dolphin', 'whale', 'puffin', 'penguin', 'squid', 'mola', 'octopus']\n",
    "\n",
    "col_name_list = []\n",
    "# for word in keywords:\n",
    "#     col_name = 'contains_word_' + word\n",
    "#     col_name_list.append(col_name)\n",
    "#     df_tweets[col_name] = df_tweets.apply(lambda row: row.favorites if word in row.text else 0, axis=1)\n",
    "\n",
    "for word in keywords:\n",
    "    col_name = 'contains_word_' + word\n",
    "    col_name_list.append(col_name)\n",
    "    df_tweets[col_name] = df_tweets.apply(lambda row: word if word in row.text else None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "      <th>contains_word_kelp</th>\n",
       "      <th>contains_word_bass</th>\n",
       "      <th>contains_word_jelly</th>\n",
       "      <th>contains_word_dolphin</th>\n",
       "      <th>contains_word_whale</th>\n",
       "      <th>contains_word_puffin</th>\n",
       "      <th>contains_word_penguin</th>\n",
       "      <th>contains_word_squid</th>\n",
       "      <th>contains_word_mola</th>\n",
       "      <th>contains_word_octopus</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_at</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-05-07 22:58:04</th>\n",
       "      <td>1125897614359007233</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>b'@Squidpastry ty mr mola fren'</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>mola</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-07 22:48:33</th>\n",
       "      <td>1125895219847688192</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>b\"@Squidpastry Like new rubber when it's new, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-07 22:47:39</th>\n",
       "      <td>1125894996018679809</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>b'@pistrix the wild Monterey Bay has that pate...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-07 22:25:25</th>\n",
       "      <td>1125889400091463680</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>b'@kumaberi Hope to sea you soon!'</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-07 22:25:07</th>\n",
       "      <td>1125889325290233856</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>b'@hcf64 1. Think like a kelp\\n2. Hard substra...</td>\n",
       "      <td>kelp</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  favorites  retweets  \\\n",
       "created_at                                                      \n",
       "2019-05-07 22:58:04  1125897614359007233          2         0   \n",
       "2019-05-07 22:48:33  1125895219847688192          1         0   \n",
       "2019-05-07 22:47:39  1125894996018679809          2         0   \n",
       "2019-05-07 22:25:25  1125889400091463680          1         0   \n",
       "2019-05-07 22:25:07  1125889325290233856          4         0   \n",
       "\n",
       "                                                                  text  \\\n",
       "created_at                                                               \n",
       "2019-05-07 22:58:04                    b'@Squidpastry ty mr mola fren'   \n",
       "2019-05-07 22:48:33  b\"@Squidpastry Like new rubber when it's new, ...   \n",
       "2019-05-07 22:47:39  b'@pistrix the wild Monterey Bay has that pate...   \n",
       "2019-05-07 22:25:25                 b'@kumaberi Hope to sea you soon!'   \n",
       "2019-05-07 22:25:07  b'@hcf64 1. Think like a kelp\\n2. Hard substra...   \n",
       "\n",
       "                    contains_word_kelp contains_word_bass contains_word_jelly  \\\n",
       "created_at                                                                      \n",
       "2019-05-07 22:58:04               None               None                None   \n",
       "2019-05-07 22:48:33               None               None                None   \n",
       "2019-05-07 22:47:39               None               None                None   \n",
       "2019-05-07 22:25:25               None               None                None   \n",
       "2019-05-07 22:25:07               kelp               None                None   \n",
       "\n",
       "                    contains_word_dolphin contains_word_whale  \\\n",
       "created_at                                                      \n",
       "2019-05-07 22:58:04                  None                None   \n",
       "2019-05-07 22:48:33                  None                None   \n",
       "2019-05-07 22:47:39                  None                None   \n",
       "2019-05-07 22:25:25                  None                None   \n",
       "2019-05-07 22:25:07                  None                None   \n",
       "\n",
       "                    contains_word_puffin contains_word_penguin  \\\n",
       "created_at                                                       \n",
       "2019-05-07 22:58:04                 None                  None   \n",
       "2019-05-07 22:48:33                 None                  None   \n",
       "2019-05-07 22:47:39                 None                  None   \n",
       "2019-05-07 22:25:25                 None                  None   \n",
       "2019-05-07 22:25:07                 None                  None   \n",
       "\n",
       "                    contains_word_squid contains_word_mola  \\\n",
       "created_at                                                   \n",
       "2019-05-07 22:58:04                None               mola   \n",
       "2019-05-07 22:48:33                None               None   \n",
       "2019-05-07 22:47:39                None               None   \n",
       "2019-05-07 22:25:25                None               None   \n",
       "2019-05-07 22:25:07                None               None   \n",
       "\n",
       "                    contains_word_octopus  \n",
       "created_at                                 \n",
       "2019-05-07 22:58:04                  None  \n",
       "2019-05-07 22:48:33                  None  \n",
       "2019-05-07 22:47:39                  None  \n",
       "2019-05-07 22:25:25                  None  \n",
       "2019-05-07 22:25:07                  None  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['contains_word_kelp',\n",
       " 'contains_word_bass',\n",
       " 'contains_word_jelly',\n",
       " 'contains_word_dolphin',\n",
       " 'contains_word_whale',\n",
       " 'contains_word_puffin',\n",
       " 'contains_word_penguin',\n",
       " 'contains_word_squid',\n",
       " 'contains_word_mola',\n",
       " 'contains_word_octopus']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_name_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Plotly plot and append new traces with tweet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_traces = []\n",
    "\n",
    "for word in keywords:\n",
    "    col_name = 'contains_word_' + word\n",
    "    trace = go.Scatter(\n",
    "        x = df_tweets.index,\n",
    "        y = df_tweets[col_name],\n",
    "        mode = 'markers',\n",
    "        marker = dict(\n",
    "            size = df_tweets['favorites']/50,\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    plotly_traces.append(trace)\n",
    "    \n",
    "fig = dict(data = plotly_traces)#, layout=layout)\n",
    "plot_url = plotly.offline.plot(fig, filename='tweet_frequency.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_at\n",
       "2019-05-07 22:58:04       2\n",
       "2019-05-07 22:48:33       1\n",
       "2019-05-07 22:47:39       2\n",
       "2019-05-07 22:25:25       1\n",
       "2019-05-07 22:25:07       4\n",
       "2019-05-07 22:16:43     166\n",
       "2019-05-07 22:11:58       5\n",
       "2019-05-07 22:00:52       1\n",
       "2019-05-07 21:51:00     931\n",
       "2019-05-07 20:32:46     117\n",
       "2019-05-07 20:09:44       3\n",
       "2019-05-07 20:06:40      83\n",
       "2019-05-07 20:01:48     563\n",
       "2019-05-07 18:28:51       2\n",
       "2019-05-07 16:32:57       1\n",
       "2019-05-06 21:36:35       6\n",
       "2019-05-06 21:28:43       0\n",
       "2019-05-06 20:33:40     425\n",
       "2019-05-04 16:57:04     777\n",
       "2019-05-03 21:29:06    1181\n",
       "2019-05-03 20:55:16       3\n",
       "2019-05-03 20:45:49       1\n",
       "2019-05-03 16:35:34     497\n",
       "2019-05-02 22:00:18       1\n",
       "2019-05-02 21:27:01       2\n",
       "2019-05-02 21:24:55       3\n",
       "2019-05-02 20:49:30      12\n",
       "2019-05-02 20:48:30      16\n",
       "2019-05-02 20:40:32       4\n",
       "2019-05-02 20:38:34      17\n",
       "                       ... \n",
       "2018-08-31 22:36:20       3\n",
       "2018-08-31 20:52:42     327\n",
       "2018-08-31 20:39:02      22\n",
       "2018-08-31 20:35:45       5\n",
       "2018-08-31 20:30:18    1220\n",
       "2018-08-31 17:56:46      87\n",
       "2018-08-31 15:00:04       1\n",
       "2018-08-30 23:43:32      14\n",
       "2018-08-30 22:41:54      40\n",
       "2018-08-30 22:41:53    1085\n",
       "2018-08-30 22:06:57       0\n",
       "2018-08-30 22:06:26       2\n",
       "2018-08-30 22:06:09       1\n",
       "2018-08-30 22:05:52       1\n",
       "2018-08-30 21:58:09       1\n",
       "2018-08-30 21:51:38       1\n",
       "2018-08-30 21:34:51       1\n",
       "2018-08-30 21:29:32       2\n",
       "2018-08-30 20:16:20       1\n",
       "2018-08-30 20:13:25       1\n",
       "2018-08-30 18:01:36     263\n",
       "2018-08-30 17:01:13       1\n",
       "2018-08-30 16:59:21       0\n",
       "2018-08-30 16:58:30       0\n",
       "2018-08-30 16:58:13       2\n",
       "2018-08-30 16:56:26       0\n",
       "2018-08-30 02:37:33       1\n",
       "2018-08-30 02:22:41       1\n",
       "2018-08-30 00:16:40       1\n",
       "2018-08-30 00:15:05       1\n",
       "Name: favorites, Length: 3232, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets['favorites']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-05-07 22:58:04', '2019-05-07 22:48:33',\n",
       "               '2019-05-07 22:47:39', '2019-05-07 22:25:25',\n",
       "               '2019-05-07 22:25:07', '2019-05-07 22:16:43',\n",
       "               '2019-05-07 22:11:58', '2019-05-07 22:00:52',\n",
       "               '2019-05-07 21:51:00', '2019-05-07 20:32:46',\n",
       "               ...\n",
       "               '2018-08-30 18:01:36', '2018-08-30 17:01:13',\n",
       "               '2018-08-30 16:59:21', '2018-08-30 16:58:30',\n",
       "               '2018-08-30 16:58:13', '2018-08-30 16:56:26',\n",
       "               '2018-08-30 02:37:33', '2018-08-30 02:22:41',\n",
       "               '2018-08-30 00:16:40', '2018-08-30 00:15:05'],\n",
       "              dtype='datetime64[ns]', name='created_at', length=3232, freq=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
